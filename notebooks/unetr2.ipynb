{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import logging as log\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from src import LOG_DIR, DATA_DIR, MODEL_DIR\n",
    "from src.utils.utils import setup\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    ToTensord,\n",
    "    EnsureType,\n",
    "    Activations,\n",
    "\n",
    ")\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNETR\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.captureWarnings(True)\n",
    "log.basicConfig(filename=os.path.join(LOG_DIR, \"train.log\"), level=log.DEBUG, \n",
    "                filemode=\"w\", format='%(asctime)s %(levelname)6s %(message)7s', datefmt='%d-%m-%Y %I:%M:%S %p')\n",
    "\n",
    "log.info(\"Running Setup..\")\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Hyperparameters\n",
    "\n",
    "### Transforms Hyperparameters\n",
    "a_min = -200\n",
    "a_max = 200\n",
    "\n",
    "### Unet Hyperparameters\n",
    "num_samples = 4\n",
    "roi_size = (96, 96, 96)\n",
    "feature_size = 16\n",
    "hidden_size = 768\n",
    "mlp_dim = 3072\n",
    "num_heads = 12\n",
    "dropout_rate = 0.0\n",
    "\n",
    "### Training Hyperparameters\n",
    "max_epochs = 1300\n",
    "batch_size = 1\n",
    "lr = 1e-4\n",
    "\n",
    "hyperparams = {\n",
    "    \"a_min\": a_min,\n",
    "    \"a_max\": a_max,\n",
    "    \"num_samples\": num_samples,\n",
    "    \"img_size\": roi_size,\n",
    "    \"feature_size\": feature_size,\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"mlp_dim\": mlp_dim,\n",
    "    \"num_heads\": num_heads,\n",
    "    \"dropout_rate\": dropout_rate,\n",
    "    \"max_epochs\": max_epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"lr\": lr\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"Defining training transforms..\")\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=a_min,\n",
    "            a_max=a_max,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=roi_size,\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=num_samples,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "log.info(\"Defining validation transforms..\")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=a_min,\n",
    "            a_max=a_max,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"Loading Data ...\")\n",
    "\n",
    "data_dir = DATA_DIR\n",
    "split_JSON = \"dataset.json\"\n",
    "datasets = data_dir + split_JSON\n",
    "datalist = load_decathlon_datalist(datasets, True, \"train\")\n",
    "val_files = load_decathlon_datalist(datasets, True, \"val\")\n",
    "\n",
    "train_ds = CacheDataset(\n",
    "    data=datalist,\n",
    "    transform=train_transforms,\n",
    "    cache_num=24,\n",
    "    cache_rate=1.0,\n",
    "    num_workers=8,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=1, shuffle=True, num_workers=8, pin_memory=True\n",
    ")\n",
    "\n",
    "val_ds = CacheDataset(\n",
    "    data=val_files, transform=val_transforms, cache_num=6, cache_rate=1.0, num_workers=4\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=1, shuffle=False, num_workers=4, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"Initializing Model ...\")\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    img_size=roi_size,\n",
    "    feature_size=feature_size,\n",
    "    hidden_size=hidden_size,\n",
    "    mlp_dim=mlp_dim,\n",
    "    num_heads=num_heads,\n",
    "    pos_embed=\"conv\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    conv_block=True,\n",
    "    dropout_rate=dropout_rate,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "log.info(\"Defining Loss ...\")\n",
    "loss_function = DiceCELoss(sigmoid=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "log.info(\"Defining Optimizer ...\")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch_iterator_val):\n",
    "    model.eval()\n",
    "    dice_vals = list()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(epoch_iterator_val):\n",
    "            val_inputs, val_labels = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "\n",
    "            val_outputs = sliding_window_inference(val_inputs, roi_size, 4, model)\n",
    "            val_outputs_list = decollate_batch(val_outputs)\n",
    "            val_output_convert = [\n",
    "                post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list\n",
    "            ]\n",
    "\n",
    "            # val_labels_list = decollate_batch(val_labels)\n",
    "            # val_labels_convert = [\n",
    "            #     post_label(val_label_tensor) for val_label_tensor in val_labels_list\n",
    "            # ]\n",
    "            \n",
    "            dice_metric(y_pred=val_output_convert, y=val_labels)\n",
    "            dice = dice_metric.aggregate().item()\n",
    "            dice_vals.append(dice)\n",
    "            \n",
    "            epoch_iterator_val.set_description(\n",
    "                \"Validate (%d / %d Steps) (dice=%2.5f)\" % (global_step, 10.0, dice)\n",
    "            )\n",
    "       \n",
    "        dice_metric.reset()\n",
    "    \n",
    "    mean_dice_val = np.mean(dice_vals)\n",
    "    return mean_dice_val\n",
    "\n",
    "\n",
    "def train(global_step, train_loader, dice_val_best, global_step_best):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    epoch_iterator = tqdm(\n",
    "        train_loader, desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True\n",
    "    )\n",
    "\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        step += 1\n",
    "        x, y = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "        logit_map = model(x)\n",
    "        loss = loss_function(logit_map, y)\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_iterator.set_description(\n",
    "            \"Training (%d / %d Steps) (loss=%2.5f)\" % (global_step, max_iterations, loss)\n",
    "        )\n",
    "\n",
    "        if (global_step % eval_num == 0 and global_step != 0) or global_step == max_iterations:\n",
    "            epoch_iterator_val = tqdm(\n",
    "                val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True\n",
    "            )\n",
    "            dice_val = validation(epoch_iterator_val)\n",
    "            epoch_loss /= step\n",
    "            epoch_loss_values.append(epoch_loss)\n",
    "            metric_values.append(dice_val)\n",
    "            if dice_val > dice_val_best:\n",
    "                dice_val_best = dice_val\n",
    "                global_step_best = global_step\n",
    "\n",
    "                torch.save(\n",
    "                    model.state_dict(), os.path.join(MODEL_DIR, \"best_metric_model.pth\")\n",
    "                )\n",
    "\n",
    "                print(f\"Model Was Saved ! Current Best Avg. Dice: {dice_val_best} Current Avg. Dice: {dice_val}\")\n",
    "            else:\n",
    "                print(f\"Model Was Not Saved ! Current Best Avg. Dice: {dice_val_best} Current Avg. Dice: {dice_val}\")\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "    return global_step, dice_val_best, global_step_best\n",
    "\n",
    "\n",
    "max_iterations = 25000\n",
    "eval_num = 500\n",
    "\n",
    "post_label = AsDiscrete(to_onehot=14)\n",
    "post_pred = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "\n",
    "global_step = 0\n",
    "dice_val_best = 0.0\n",
    "global_step_best = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "\n",
    "while global_step < max_iterations:\n",
    "    global_step, dice_val_best, global_step_best = train(\n",
    "        global_step, train_loader, dice_val_best, global_step_best\n",
    "    )\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"best_metric_model.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5548b056300868dedb42435ffdfc978c919aa00c8119c91af3e1ba265e18c3e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('segment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
